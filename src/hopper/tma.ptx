//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-35059454
// Cuda compilation tools, release 12.6, V12.6.85
// Based on NVVM 7.0.1
//

.version 8.5
.target sm_90a
.address_size 64

	// .globl	_Z10tma_kernelILi64ELi64EEv14CUtensorMap_stP6__halfii
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
// _ZZ10tma_kernelILi64ELi64EEv14CUtensorMap_stP6__halfiiE4smem has been demoted
// _ZZ10tma_kernelILi64ELi64EEv14CUtensorMap_stP6__halfiiE4full has been demoted
// _ZZ10tma_kernelILi64ELi64EEv14CUtensorMap_stP6__halfiiE5empty has been demoted
.global .align 1 .b8 $str[2] = {10};
.global .align 1 .b8 $str$1[4] = {37, 102, 9};

.visible .entry _Z10tma_kernelILi64ELi64EEv14CUtensorMap_stP6__halfii(
	.param .align 64 .b8 _Z10tma_kernelILi64ELi64EEv14CUtensorMap_stP6__halfii_param_0[128],
	.param .u64 _Z10tma_kernelILi64ELi64EEv14CUtensorMap_stP6__halfii_param_1,
	.param .u32 _Z10tma_kernelILi64ELi64EEv14CUtensorMap_stP6__halfii_param_2,
	.param .u32 _Z10tma_kernelILi64ELi64EEv14CUtensorMap_stP6__halfii_param_3
)
{
	.local .align 8 .b8 	__local_depot0[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<17>;
	.reg .f32 	%f<17>;
	.reg .b32 	%r<47>;
	.reg .f64 	%fd<17>;
	.reg .b64 	%rd<15>;
	// demoted variable
	.shared .align 128 .b8 _ZZ10tma_kernelILi64ELi64EEv14CUtensorMap_stP6__halfiiE4smem[8192];
	// demoted variable
	.shared .align 8 .u64 _ZZ10tma_kernelILi64ELi64EEv14CUtensorMap_stP6__halfiiE4full;
	// demoted variable
	.shared .align 8 .u64 _ZZ10tma_kernelILi64ELi64EEv14CUtensorMap_stP6__halfiiE5empty;

	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	mov.b64 	%rd2, _Z10tma_kernelILi64ELi64EEv14CUtensorMap_stP6__halfii_param_0;
	mov.u32 	%r1, %tid.x;
	setp.ne.s32 	%p1, %r1, 0;
	@%p1 bra 	$L__BB0_2;

	mov.u32 	%r6, _ZZ10tma_kernelILi64ELi64EEv14CUtensorMap_stP6__halfiiE4full;
	mov.u32 	%r9, 1;
	// begin inline asm
	mbarrier.init.shared::cta.b64 [%r6], %r9; 

	// end inline asm
	mov.u32 	%r8, _ZZ10tma_kernelILi64ELi64EEv14CUtensorMap_stP6__halfiiE5empty;
	// begin inline asm
	mbarrier.init.shared::cta.b64 [%r8], %r9; 

	// end inline asm

$L__BB0_2:
	bar.sync 	0;
	@%p1 bra 	$L__BB0_7;

	add.u64 	%rd4, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r10, _ZZ10tma_kernelILi64ELi64EEv14CUtensorMap_stP6__halfiiE5empty;
	mov.u32 	%r11, 1;
	// begin inline asm
	mbarrier.arrive.release.cta.shared::cta.b64 _, [%r10], %r11;

	// end inline asm
	mov.u32 	%r12, _ZZ10tma_kernelILi64ELi64EEv14CUtensorMap_stP6__halfiiE4full;
	mov.u32 	%r13, 8192;
	// begin inline asm
	mbarrier.arrive.expect_tx.release.cta.shared::cta.b64 _, [%r12], %r13;

	// end inline asm
	mov.u32 	%r21, 0;
	// begin inline asm
	{
.reg .pred        P1;
LAB_WAIT:
mbarrier.try_wait.parity.acquire.cta.shared::cta.b64 P1,[%r10], %r21;
@P1             bra.uni DONE;
bra.uni         LAB_WAIT;
DONE:
}

	// end inline asm
	cvta.param.u64 	%rd3, %rd2;
	mov.u32 	%r16, _ZZ10tma_kernelILi64ELi64EEv14CUtensorMap_stP6__halfiiE4smem;
	// begin inline asm
	cp.async.bulk.tensor.5d.shared::cluster.global.tile.mbarrier::complete_tx::bytes[%r16], [%rd3, {%r21, %r21, 0, 0, 0}], [%r12];
	// end inline asm
	// begin inline asm
	{
.reg .pred        P1;
LAB_WAIT:
mbarrier.try_wait.parity.acquire.cta.shared::cta.b64 P1,[%r12], %r21;
@P1             bra.uni DONE;
bra.uni         LAB_WAIT;
DONE:
}

	// end inline asm
	mov.u32 	%r46, 128;
	mov.u32 	%r45, -64;
	mov.u64 	%rd6, $str;
	cvta.global.u64 	%rd7, %rd6;
	mov.u64 	%rd8, $str$1;
	cvta.global.u64 	%rd9, %rd8;

$L__BB0_4:
	setp.eq.s32 	%p3, %r45, -64;
	@%p3 bra 	$L__BB0_6;

	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64 	[param1+0], 0;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r24, [retval0+0];
	} // callseq 0

$L__BB0_6:
	add.s32 	%r26, %r16, %r46;
	ld.shared.u16 	%rs1, [%r26+-128];
	// begin inline asm
	{  cvt.f32.f16 %f1, %rs1;}

	// end inline asm
	cvt.f64.f32 	%fd1, %f1;
	st.local.f64 	[%rd1], %fd1;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r27, [retval0+0];
	} // callseq 1
	ld.shared.u16 	%rs2, [%r26+-112];
	// begin inline asm
	{  cvt.f32.f16 %f2, %rs2;}

	// end inline asm
	cvt.f64.f32 	%fd2, %f2;
	st.local.f64 	[%rd1], %fd2;
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r28, [retval0+0];
	} // callseq 2
	ld.shared.u16 	%rs3, [%r26+-96];
	// begin inline asm
	{  cvt.f32.f16 %f3, %rs3;}

	// end inline asm
	cvt.f64.f32 	%fd3, %f3;
	st.local.f64 	[%rd1], %fd3;
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r29, [retval0+0];
	} // callseq 3
	ld.shared.u16 	%rs4, [%r26+-80];
	// begin inline asm
	{  cvt.f32.f16 %f4, %rs4;}

	// end inline asm
	cvt.f64.f32 	%fd4, %f4;
	st.local.f64 	[%rd1], %fd4;
	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r30, [retval0+0];
	} // callseq 4
	ld.shared.u16 	%rs5, [%r26+-64];
	// begin inline asm
	{  cvt.f32.f16 %f5, %rs5;}

	// end inline asm
	cvt.f64.f32 	%fd5, %f5;
	st.local.f64 	[%rd1], %fd5;
	{ // callseq 5, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r31, [retval0+0];
	} // callseq 5
	ld.shared.u16 	%rs6, [%r26+-48];
	// begin inline asm
	{  cvt.f32.f16 %f6, %rs6;}

	// end inline asm
	cvt.f64.f32 	%fd6, %f6;
	st.local.f64 	[%rd1], %fd6;
	{ // callseq 6, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r32, [retval0+0];
	} // callseq 6
	ld.shared.u16 	%rs7, [%r26+-32];
	// begin inline asm
	{  cvt.f32.f16 %f7, %rs7;}

	// end inline asm
	cvt.f64.f32 	%fd7, %f7;
	st.local.f64 	[%rd1], %fd7;
	{ // callseq 7, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r33, [retval0+0];
	} // callseq 7
	ld.shared.u16 	%rs8, [%r26+-16];
	// begin inline asm
	{  cvt.f32.f16 %f8, %rs8;}

	// end inline asm
	cvt.f64.f32 	%fd8, %f8;
	st.local.f64 	[%rd1], %fd8;
	{ // callseq 8, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r34, [retval0+0];
	} // callseq 8
	{ // callseq 9, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64 	[param1+0], 0;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r35, [retval0+0];
	} // callseq 9
	ld.shared.u16 	%rs9, [%r26];
	// begin inline asm
	{  cvt.f32.f16 %f9, %rs9;}

	// end inline asm
	cvt.f64.f32 	%fd9, %f9;
	st.local.f64 	[%rd1], %fd9;
	{ // callseq 10, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r36, [retval0+0];
	} // callseq 10
	ld.shared.u16 	%rs10, [%r26+16];
	// begin inline asm
	{  cvt.f32.f16 %f10, %rs10;}

	// end inline asm
	cvt.f64.f32 	%fd10, %f10;
	st.local.f64 	[%rd1], %fd10;
	{ // callseq 11, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r37, [retval0+0];
	} // callseq 11
	ld.shared.u16 	%rs11, [%r26+32];
	// begin inline asm
	{  cvt.f32.f16 %f11, %rs11;}

	// end inline asm
	cvt.f64.f32 	%fd11, %f11;
	st.local.f64 	[%rd1], %fd11;
	{ // callseq 12, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r38, [retval0+0];
	} // callseq 12
	ld.shared.u16 	%rs12, [%r26+48];
	// begin inline asm
	{  cvt.f32.f16 %f12, %rs12;}

	// end inline asm
	cvt.f64.f32 	%fd12, %f12;
	st.local.f64 	[%rd1], %fd12;
	{ // callseq 13, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r39, [retval0+0];
	} // callseq 13
	ld.shared.u16 	%rs13, [%r26+64];
	// begin inline asm
	{  cvt.f32.f16 %f13, %rs13;}

	// end inline asm
	cvt.f64.f32 	%fd13, %f13;
	st.local.f64 	[%rd1], %fd13;
	{ // callseq 14, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r40, [retval0+0];
	} // callseq 14
	ld.shared.u16 	%rs14, [%r26+80];
	// begin inline asm
	{  cvt.f32.f16 %f14, %rs14;}

	// end inline asm
	cvt.f64.f32 	%fd14, %f14;
	st.local.f64 	[%rd1], %fd14;
	{ // callseq 15, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r41, [retval0+0];
	} // callseq 15
	ld.shared.u16 	%rs15, [%r26+96];
	// begin inline asm
	{  cvt.f32.f16 %f15, %rs15;}

	// end inline asm
	cvt.f64.f32 	%fd15, %f15;
	st.local.f64 	[%rd1], %fd15;
	{ // callseq 16, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r42, [retval0+0];
	} // callseq 16
	ld.shared.u16 	%rs16, [%r26+112];
	// begin inline asm
	{  cvt.f32.f16 %f16, %rs16;}

	// end inline asm
	cvt.f64.f32 	%fd16, %f16;
	st.local.f64 	[%rd1], %fd16;
	{ // callseq 17, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r43, [retval0+0];
	} // callseq 17
	add.s32 	%r45, %r45, 2;
	add.s32 	%r46, %r46, 256;
	setp.ne.s32 	%p4, %r46, 8320;
	@%p4 bra 	$L__BB0_4;

$L__BB0_7:
	mov.u64 	%rd13, $str;
	cvta.global.u64 	%rd14, %rd13;
	{ // callseq 18, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd14;
	.param .b64 param1;
	st.param.b64 	[param1+0], 0;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r44, [retval0+0];
	} // callseq 18
	ret;

}

